{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Computer Vision](https://www.kaggle.com/learn/computer-vision) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/custom-convnets).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction #\n\nIn these exercises, you'll build a custom convnet with performance competitive to the VGG16 model from Lesson 1.\n\nGet started by running the code cell below.","metadata":{}},{"cell_type":"code","source":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.computer_vision.ex5 import *\n\n# Imports\nimport os, warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n# Reproducability\ndef set_seed(seed=31415):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()\n\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\n# Load training and validation sets\nds_train_ = image_dataset_from_directory(\n    '../input/car-or-truck/train',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\nds_valid_ = image_dataset_from_directory(\n    '../input/car-or-truck/valid',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=False,\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-18T10:52:56.909840Z","iopub.execute_input":"2021-08-18T10:52:56.910252Z","iopub.status.idle":"2021-08-18T10:53:07.019936Z","shell.execute_reply.started":"2021-08-18T10:52:56.910172Z","shell.execute_reply":"2021-08-18T10:53:07.018840Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found 5117 files belonging to 2 classes.\nFound 5051 files belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Design a Convnet #\n\nLet's design a convolutional network with a block architecture like we saw in the tutorial. The model from the example had three blocks, each with a single convolutional layer. Its performance on the \"Car or Truck\" problem was okay, but far from what the pretrained VGG16 could achieve. It might be that our simple network lacks the ability to extract sufficiently complex features. We could try improving the model either by adding more blocks or by adding convolutions to the blocks we have.\n\nLet's go with the second approach. We'll keep the three block structure, but increase the number of `Conv2D` layer in the second block to two, and in the third block to three.\n\n<figure>\n<!-- <img src=\"./images/2-convmodel-2.png\" width=\"250\" alt=\"Diagram of a convolutional model.\"> -->\n<img src=\"https://i.imgur.com/Vko6nCK.png\" width=\"250\" alt=\"Diagram of a convolutional model.\">\n</figure>\n\n# 1) Define Model #\n\nGiven the diagram above, complete the model by defining the layers of the third block.","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[128, 128, 3]),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Three\n    # YOUR CODE HERE\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(6, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(1, activation='sigmoid'),\n])\n\n# Check your answer\nq_1.check()","metadata":{"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2021-08-18T10:53:43.409280Z","iopub.execute_input":"2021-08-18T10:53:43.409777Z","iopub.status.idle":"2021-08-18T10:53:43.531833Z","shell.execute_reply.started":"2021-08-18T10:53:43.409747Z","shell.execute_reply":"2021-08-18T10:53:43.530973Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_Q1\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq_1.hint()\nq_1.solution()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T10:53:45.677714Z","iopub.execute_input":"2021-08-18T10:53:45.678096Z","iopub.status.idle":"2021-08-18T10:53:45.689440Z","shell.execute_reply.started":"2021-08-18T10:53:45.678067Z","shell.execute_reply":"2021-08-18T10:53:45.688585Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"questionId\": \"1_Q1\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: You should add two `Conv2D` layers and then a `MaxPool2D` layer. They will be just the same as the other layers in the model, except for some of the parameter values.","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> You should add two `Conv2D` layers and then a `MaxPool2D` layer. They will be just the same as the other layers in the model, except for some of the parameter values."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"questionId\": \"1_Q1\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[128, 128, 3]),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(6, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(1, activation='sigmoid'),\n])\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[128, 128, 3]),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(6, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(1, activation='sigmoid'),\n])\n\n```"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2) Compile #\n\nTo prepare for training, compile the model with an appropriate loss and accuracy metric for the \"Car or Truck\" dataset.","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n    # YOUR CODE HERE: Add loss and metric\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy']\n)\n\n# Check your answer\nq_2.check()","metadata":{"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2021-08-18T10:53:49.388272Z","iopub.execute_input":"2021-08-18T10:53:49.388797Z","iopub.status.idle":"2021-08-18T10:53:49.407743Z","shell.execute_reply.started":"2021-08-18T10:53:49.388752Z","shell.execute_reply":"2021-08-18T10:53:49.406726Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_Q2\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\nq_2.assert_check_passed()","metadata":{"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2021-08-18T10:53:51.567804Z","iopub.execute_input":"2021-08-18T10:53:51.568183Z","iopub.status.idle":"2021-08-18T10:53:51.584735Z","shell.execute_reply.started":"2021-08-18T10:53:51.568141Z","shell.execute_reply":"2021-08-18T10:53:51.583603Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_Q2\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq_2.hint()\nq_2.solution()","metadata":{"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2021-08-18T10:53:53.441578Z","iopub.execute_input":"2021-08-18T10:53:53.442131Z","iopub.status.idle":"2021-08-18T10:53:53.451274Z","shell.execute_reply.started":"2021-08-18T10:53:53.442099Z","shell.execute_reply":"2021-08-18T10:53:53.450584Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"questionId\": \"2_Q2\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: This is a *binary* classification problem.","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> This is a *binary* classification problem."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"questionId\": \"2_Q2\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\n```"},"metadata":{}}]},{"cell_type":"markdown","source":"Finally, let's test the performance of this new model. First run this cell to fit the model to the training set.","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=50,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T10:53:55.736596Z","iopub.execute_input":"2021-08-18T10:53:55.737007Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50\n80/80 [==============================] - 191s 2s/step - loss: 0.6878 - binary_accuracy: 0.5587 - val_loss: 0.6691 - val_binary_accuracy: 0.5785\nEpoch 2/50\n80/80 [==============================] - 190s 2s/step - loss: 0.6676 - binary_accuracy: 0.5748 - val_loss: 0.6623 - val_binary_accuracy: 0.5785\nEpoch 3/50\n80/80 [==============================] - 181s 2s/step - loss: 0.6642 - binary_accuracy: 0.5748 - val_loss: 0.6505 - val_binary_accuracy: 0.5785\nEpoch 4/50\n80/80 [==============================] - 182s 2s/step - loss: 0.6542 - binary_accuracy: 0.5748 - val_loss: 0.6461 - val_binary_accuracy: 0.5785\nEpoch 5/50\n80/80 [==============================] - 194s 2s/step - loss: 0.6536 - binary_accuracy: 0.5778 - val_loss: 0.6389 - val_binary_accuracy: 0.5965\nEpoch 6/50\n80/80 [==============================] - 184s 2s/step - loss: 0.6418 - binary_accuracy: 0.6178 - val_loss: 0.6348 - val_binary_accuracy: 0.5939\nEpoch 7/50\n80/80 [==============================] - 184s 2s/step - loss: 0.6418 - binary_accuracy: 0.6228 - val_loss: 0.6311 - val_binary_accuracy: 0.5985\nEpoch 8/50\n80/80 [==============================] - 192s 2s/step - loss: 0.6358 - binary_accuracy: 0.6375 - val_loss: 0.6269 - val_binary_accuracy: 0.6242\nEpoch 9/50\n80/80 [==============================] - 183s 2s/step - loss: 0.6326 - binary_accuracy: 0.6465 - val_loss: 0.6163 - val_binary_accuracy: 0.6454\nEpoch 10/50\n80/80 [==============================] - 182s 2s/step - loss: 0.6234 - binary_accuracy: 0.6606 - val_loss: 0.6110 - val_binary_accuracy: 0.6531\nEpoch 11/50\n80/80 [==============================] - 182s 2s/step - loss: 0.6119 - binary_accuracy: 0.6709 - val_loss: 0.5948 - val_binary_accuracy: 0.6771\nEpoch 12/50\n80/80 [==============================] - 190s 2s/step - loss: 0.6012 - binary_accuracy: 0.6691 - val_loss: 0.5835 - val_binary_accuracy: 0.6900\nEpoch 13/50\n80/80 [==============================] - 181s 2s/step - loss: 0.5867 - binary_accuracy: 0.6858 - val_loss: 0.5744 - val_binary_accuracy: 0.7009\nEpoch 14/50\n80/80 [==============================] - 183s 2s/step - loss: 0.5677 - binary_accuracy: 0.7052 - val_loss: 0.5663 - val_binary_accuracy: 0.7012\nEpoch 15/50\n80/80 [==============================] - 192s 2s/step - loss: 0.5536 - binary_accuracy: 0.7290 - val_loss: 0.5434 - val_binary_accuracy: 0.7292\nEpoch 16/50\n80/80 [==============================] - 182s 2s/step - loss: 0.5324 - binary_accuracy: 0.7370 - val_loss: 0.5307 - val_binary_accuracy: 0.7385\nEpoch 17/50\n80/80 [==============================] - 182s 2s/step - loss: 0.5054 - binary_accuracy: 0.7519 - val_loss: 0.5043 - val_binary_accuracy: 0.7591\nEpoch 18/50\n80/80 [==============================] - 191s 2s/step - loss: 0.4741 - binary_accuracy: 0.7732 - val_loss: 0.4828 - val_binary_accuracy: 0.7624\nEpoch 19/50\n80/80 [==============================] - 181s 2s/step - loss: 0.4399 - binary_accuracy: 0.8042 - val_loss: 0.4723 - val_binary_accuracy: 0.7745\nEpoch 20/50\n80/80 [==============================] - 182s 2s/step - loss: 0.4132 - binary_accuracy: 0.8103 - val_loss: 0.4649 - val_binary_accuracy: 0.7905\nEpoch 21/50\n80/80 [==============================] - 181s 2s/step - loss: 0.3863 - binary_accuracy: 0.8321 - val_loss: 0.4536 - val_binary_accuracy: 0.7971\nEpoch 22/50\n80/80 [==============================] - 190s 2s/step - loss: 0.3607 - binary_accuracy: 0.8387 - val_loss: 0.4553 - val_binary_accuracy: 0.8084\nEpoch 23/50\n80/80 [==============================] - 181s 2s/step - loss: 0.3510 - binary_accuracy: 0.8511 - val_loss: 0.4691 - val_binary_accuracy: 0.8119\nEpoch 24/50\n80/80 [==============================] - 181s 2s/step - loss: 0.3055 - binary_accuracy: 0.8696 - val_loss: 0.4506 - val_binary_accuracy: 0.8054\nEpoch 25/50\n80/80 [==============================] - 194s 2s/step - loss: 0.3030 - binary_accuracy: 0.8698 - val_loss: 0.4545 - val_binary_accuracy: 0.7899\nEpoch 26/50\n80/80 [==============================] - 184s 2s/step - loss: 0.2965 - binary_accuracy: 0.8748 - val_loss: 0.5495 - val_binary_accuracy: 0.7684\nEpoch 27/50\n80/80 [==============================] - 181s 2s/step - loss: 0.3019 - binary_accuracy: 0.8754 - val_loss: 0.5143 - val_binary_accuracy: 0.7721\nEpoch 28/50\n80/80 [==============================] - 195s 2s/step - loss: 0.2986 - binary_accuracy: 0.8761 - val_loss: 0.4524 - val_binary_accuracy: 0.8056\nEpoch 29/50\n80/80 [==============================] - 182s 2s/step - loss: 0.2901 - binary_accuracy: 0.8742 - val_loss: 0.4773 - val_binary_accuracy: 0.8218\nEpoch 30/50\n80/80 [==============================] - 181s 2s/step - loss: 0.2413 - binary_accuracy: 0.9009 - val_loss: 0.4425 - val_binary_accuracy: 0.8260\nEpoch 31/50\n80/80 [==============================] - 182s 2s/step - loss: 0.2187 - binary_accuracy: 0.9117 - val_loss: 0.4607 - val_binary_accuracy: 0.8289\nEpoch 32/50\n19/80 [======>.......................] - ETA: 2:01 - loss: 0.1842 - binary_accuracy: 0.9222","output_type":"stream"}]},{"cell_type":"markdown","source":"And now run the cell below to plot the loss and metric curves for this training run.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Train the Model #\n\nHow would you interpret these training curves? Did this model improve upon the model from the tutorial?","metadata":{}},{"cell_type":"code","source":"# View the solution (Run this code cell to receive credit!)\nq_3.check()","metadata":{"lines_to_next_cell":0,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion #\n\nThese exercises showed you how to design a custom convolutional network to solve a specific classification problem. Though most models these days will be built on top of a pretrained base, it certain circumstances a smaller custom convnet might still be preferable -- such as with a smaller or unusual dataset or when computing resources are very limited. As you saw here, for certain problems they can perform just as well as a pretrained model.\n\n# Keep Going #\n\nContinue on to [**Lesson 6**](https://www.kaggle.com/ryanholbrook/data-augmentation), where you'll learn a widely-used technique that can give a boost to your training data: **data augmentation**.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/196537) to chat with other Learners.*","metadata":{}}]}